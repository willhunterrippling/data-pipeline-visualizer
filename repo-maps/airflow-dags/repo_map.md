# Airflow DAGs Repository Map

> **Machine-readable version:** [`repo_map.json`](repo_map.json)

## What This Repo Is

- **Airflow-based data pipeline orchestration** for Rippling (346 DAGs across 26 domains)
- **Snowflake as primary data warehouse** - all SQL transformations via `SnowflakeOperator`
- **No dbt present** - README notes transition to [rippling-dbt](https://github.com/Rippling/rippling-dbt) is underway

## Key Directories

| Path | Purpose | Count |
|------|---------|-------|
| `airflow_dags/dags/` | DAG definitions by domain | 346 .py files |
| `airflow_dags/resources/` | SQL, YAML configs, Python scripts | 696 SQL, 200 YAML |
| `airflow_dags/airflow_apps/data_quality/` | DAG factory for DQ checks | [`dagfactory.py`](airflow_dags/airflow_apps/data_quality/dagfactory.py) |
| `airflow_dags/great_expectations_tools/` | Data quality utilities | GE integration |

## DAG Distribution by Domain

| Domain | DAGs | SQL Files | Description |
|--------|------|-----------|-------------|
| **growth** | 131 | 353 | Mechanized outreach, lead enrichment, audiences |
| **dwh** | 58 | 116 | Core data warehouse tables |
| **analytics** | 38 | 46 | Business metrics, reporting |
| **bizops** | 25 | 26 | Operational data |
| **risk** | 19 | 23 | Risk modeling, financial monitoring |
| **data_engg** | 18 | 10 | Platform utilities |
| **finance** | 10 | 48 | Financial data pipelines |
| Other (19 domains) | 47 | 74 | Various |

## SQL Loading Pattern

```python
# DAGs load SQL via DagUtils helper
sql = DagUtils.get_sql_query_from_path(
    module_folder="dwh",           # → airflow_dags/resources/dwh/sqls/
    file_name="fact_booking.sql"   # → airflow_dags/resources/dwh/sqls/fact_booking.sql
)
```

## Naming Conventions

| Element | Pattern | Examples |
|---------|---------|----------|
| **DAGs** | `{domain}_{entity}_{frequency}` | `dwh_dim_fact_booking_line_item`, `risk_fact_payroll` |
| **SQL files** | `stg_*`, `dim_*`, `fact_*`, `rpt_*` | `stg_fact_booking.sql`, `dim_account.sql` |
| **Schemas** | Domain-based | `DWH`, `STAGING_CDC_DWH`, `GROWTH`, `RISK`, `SFDC` |

## Flow Candidates

| Flow | Anchor Tables | Key DAGs |
|------|---------------|----------|
| **Mechanized Outreach** | `MASTER_MECH_OUTREACH_LEADS`, `MO_POPULATION` | `new_mech_outreach_leads_table_dag_with_suppression` |
| **Automated Intent** | `AUTOMATED_INTENT_LEADS`, population tables | `batch_map_automated_intent_leads_to_sequences` |
| **Booking Line Item** | `dwh.fact_booking_line_item`, `dim_*` | `dwh_dim_fact_booking_line_item` |
| **Lead Enrichment** | `LSW_LEADS`, vendor output tables | `lead_search_scheduling_dag`, `lead_enrichment_scheduling_dag` |
| **Cross-sell Audiences** | `PREFILTERED_XSELL_EMAIL`, cohort tables | `batch_refresh_audience_population` |
| **Risk Data Models** | `RISK.fact_ledger_entry`, `dim_ach` | `risk_fact_ledger_entry` (*/20 min) |

## Grouping Rules for Lineage

1. **By domain folder** - DAGs and resources mirror each other (`dags/growth/` ↔ `resources/growth/`)
2. **By table prefix** - `stg_* → dim_* → fact_*` follows dimensional modeling flow
3. **By DAG tag** - Airflow UI groups by `tags=["dwh"]`, `tags=["growth"]`, etc.
4. **By Snowflake schema** - `DWH.*`, `GROWTH.*`, `RISK.*` map to business domains

## Jinja/Macro Patterns

| Pattern | Impact |
|---------|--------|
| `{{ params.schema }}` | Dynamic schema (GROWTH in prod) |
| `{{ params.table }}` | Dynamic table name in generic templates |
| `{{ params.run_dt }}` | Runtime timestamp for incremental loads |
| `DagUtils.is_prod_env()` | Schedule only active in production |

## Ambiguities / Gotchas

1. **Dynamic SQL params** - Many SQLs use `{{ params.schema }}.{{ params.table }}` - actual values in DAG Python files
2. **No manifest.json** - Lineage must be inferred from SQL parsing (dbt transition pending)
3. **Auto-generated DAGs** - Look for `@generated by airflow_dag_generator` comment
4. **Environment branching** - Schedules are `None` in dev, only active in prod
5. **External integrations** - Salesforce, ZoomInfo, Apollo, Crunchbase APIs defined in `constants.py`

## How to Compile/Run

```bash
# Setup
make poetry-install
make clean clean-dev setup-dev

# Generate a DAG from YAML config
source .venv/bin/activate
airflow_dag_generator --dag-config-file-path "./airflow_dags/resources/{domain}/configs/{name}.yml" -O

# Deploy to dev
make deploy-to-dev
```

## Citations

- Repository overview: [`README.md:1-12`](README.md)
- DAG generator docs: [`README.md:42-179`](README.md)
- Domain defaults example: [`airflow_dags/resources/dwh/defaults.yml`](airflow_dags/resources/dwh/defaults.yml)
- Growth constants: [`airflow_dags/resources/growth/scripts/common/constants.py`](airflow_dags/resources/growth/scripts/common/constants.py)
- MO suppression docs: [`airflow_dags/resources/growth/sqls/mo_leads_suppression_analytics/MO_SUPPRESSION_RULES_DOCUMENTATION.md`](airflow_dags/resources/growth/sqls/mo_leads_suppression_analytics/MO_SUPPRESSION_RULES_DOCUMENTATION.md)
- Automated Intent docs: [`airflow_dags/resources/growth/sqls/automated_intent_v2/AUTOMATED_INTENT_SUPPRESSION_RULES_DOCUMENTATION.md`](airflow_dags/resources/growth/sqls/automated_intent_v2/AUTOMATED_INTENT_SUPPRESSION_RULES_DOCUMENTATION.md)

